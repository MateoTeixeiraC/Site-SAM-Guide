<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Accueil SAM-Guide</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="../css/style.css">
    <link href="https://fonts.googleapis.com/css2?family=Inria+Sans:wght@300;400;700&display=swap" rel="stylesheet">
</head>
<body>
    <header class="site-header">
        <div class="language-switch">
          <button>FR</button>
          <button>EN</button>
        </div>
      
        <h1 class="site-title"><a href="../index.html" style="text-decoration: none; color: inherit;">SAM-Guide</a></h1>
      
        <!-- Bouton Burger -->
        <div class="burger-menu" id="burgerMenu">
          <div class="bar"></div>
          <div class="bar"></div>
          <div class="bar"></div>
        </div>
      
        <!-- Menu à afficher/masquer -->
        <nav class="nav-links" id="navLinks">
          <a href="../index.html">Accueil</a>
          <a href="../html/consortium.html">Consortium</a>
          <a href="../html/actualites.html">Actualités</a>
          <a href="../html/annonces.html">Annonces</a>
          <a href="../html/faq.html">FAQ</a>
          <a href="../html/contact.html">Contact</a>
          <a href="../html/jeu.html">Jeu Interactif</a>
        </nav>
      </header>

<main>

      <section class="intro-banner text-center py-3 text-white" style="background-color: rgb(0, 57, 83);">
        <h2 class="m-0">Le projet SAM-Guide</h2>
      </section>
      
      <section class="container my-5" style="max-width: 1500px; margin: 0 auto;">
        <h3 class="mb-5 fw-bold text-center">Nos objectifs</h3>
      
<div class="row text-center mb-4 gx-4 gy-4">
  <div class="col-md-4">
    <div class="bg-light p-4 shadow-sm h-100 text-justify">
      <h4 class="fw-bold mt-3 mb-4 text-center">Autonomie Spatiale</h4>
      <p class="fw-medium fs-6">
        Le cœur du projet SAM-Guide est de favoriser l'autonomie des personnes aveugles ou malvoyantes dans leurs interactions avec l’espace. Qu’il s’agisse de se déplacer dans un bâtiment, de retrouver un objet ou de pratiquer une activité physique, la perte de vision rend ces tâches complexes et parfois impossibles sans assistance. L’objectif est donc de développer des outils sensoriels intuitifs qui permettent à l’utilisateur de s’orienter, de se repérer et d’interagir avec son environnement sans dépendre d’une aide humaine ou d’un guidage visuel. Ces outils doivent leur offrir la liberté de se déplacer et d'agir de manière sécurisée, fluide, et autonome.
      </p>
    </div>
  </div>
  <div class="col-md-4">
    <div class="bg-light p-4 shadow-sm h-100 text-justify">
      <h4 class="fw-bold mt-3 mb-4 text-center">Transcodage Sensoriel</h4>
      <p class="fw-medium fs-6">
        Une des ambitions majeures de SAM-Guide est de concevoir un langage sensoriel universel, capable de convertir les informations spatiales — habituellement transmises par la vision — en signaux tactiles et auditifs. Ce processus, appelé transcodage sensoriel, repose sur des principes issus des neurosciences, de la cognition spatiale et de l’ergonomie. Il s'agit de transmettre uniquement les informations essentielles, de manière intelligible et intuitive, tout en respectant les limites cognitives de l’utilisateur. L'objectif est de créer un système cohérent et modulaire, utilisable dans différentes situations et adaptable à diverses interfaces (ceinture, casque, etc.).
      </p>
    </div>
  </div>
  <div class="col-md-4">
    <div class="bg-light p-4 shadow-sm h-100 text-justify">
      <h4 class="fw-bold mt-3 mb-4 text-center">Technologies inclusives</h4>
      <p class="fw-medium fs-6">
        SAM-Guide vise à concevoir des technologies réellement accessibles, pensées pour s’adapter aux besoins spécifiques des personnes aveugles ou malvoyantes. Le projet privilégie une approche inclusive : les dispositifs développés sont légers, portables, compatibles avec les déplacements urbains ou les activités sportives, et ne nécessitent pas un apprentissage complexe. L’idée est de sortir de la logique de substitution totale de la vision, pour proposer au contraire des outils concrets, simples, et facilement intégrables dans le quotidien. En améliorant leur accessibilité à des contextes variés, ces technologies participent à une société plus juste et inclusive.
      </p>      
    </div>
  </div>
</div>
      </section>

<section class="scientific-approach my-5 px-3 px-md-5">
  <div class="inner-container">
    <div class="row g-0 align-items-center justify-content-center custom-gap">
      <!-- Texte -->
      <div class="col-md-6">
        <h3 class="mb-3 fw-bold">Notre approche scientifique</h3>
        <ul>
          <li>Étudier la perception spatiale</li>
          <li>Créer un langage sensoriel</li>
          <li>Tester en réalité augmentée</li>
          <li>Appliquer en conditions réelles</li>
        </ul>
      </div>
  
      <!-- Image -->
      <div class="col-md-6 text-center">
        <img src="../img/stade1.JPG" alt="Test sur une piste d’athlétisme" class="img-fluid rounded shadow-sm">
      </div>
    </div>
  </div>
  

  <!-- Flèches d'étapes -->
  <div class="process-flow mt-5 d-flex flex-wrap justify-content-center gap-3 text-center">
    <div class="step">Comprendre</div>
    <div class="step">Modéliser</div>
    <div class="step">Expérimenter</div>
    <div class="step">Transposer</div>
  </div>
</section>

<section class="container my-5" style="max-width: 1700px; margin: 0 auto;">
  <h3 class="mb-3 fw-bold text-center">Les technologies mobilisées</h3>
  
  <div class="row gy-4">

    <!-- Bloc 1 -->
<div class="col-md-12">
  <div class="d-md-flex align-items-stretch bg-light rounded shadow-sm overflow-hidden" style="min-height: 200px;">
    <div class="flex-grow-1 p-4">
      <h4 class="fw-bold">Ceinture Tactile</h4>
      <p class="text-justify">
        La ceinture vibratoire développée dans le cadre de SAM-Guide est un dispositif porté autour de la taille, équipé de plusieurs moteurs vibrants positionnés tout autour du corps. Chaque vibration est utilisée pour transmettre une information directionnelle : par exemple, une vibration à droite indique une direction vers la droite. Ce dispositif permet aux utilisateurs d’anticiper un virage ou de s’aligner sur un chemin, même en l’absence d’un repère visuel. L’usage de la ceinture limite les mains et l’attention mobilisées, ce qui la rend particulièrement utile dans des situations où la sécurité prime (franchissement de rues, activités sportives, etc.).
      </p>
    </div>
    <div class="w-100 w-md-auto img-technologie">
      <img src="../img/ceinture.jpg" alt="Ceinture Tactile" class="w-100 h-100 object-fit-cover">
    </div>
  </div>
</div>

<!-- Bloc 2 -->
<div class="col-md-12 mt-4">
  <div class="d-md-flex align-items-stretch bg-light rounded shadow-sm overflow-hidden" style="min-height: 200px;">
    <div class="flex-grow-1 p-4">
      <h4 class="fw-bold">Sons spatialisés</h4>
      <p class="text-justify">
        Le son spatialisé est une autre composante clé du projet. Grâce à des algorithmes de traitement audio basés sur la HRTF (Head-Related Transfer Function), les sons générés par le dispositif peuvent être perçus comme venant d’un point précis dans l’espace autour de l’utilisateur. Cela permet par exemple de localiser un objet ou un obstacle par le son. Ce dispositif améliore considérablement l’orientation et la perception de l’environnement. Cela nécessite également une précision de l'espace, en particulier dans les environnements complexes ou dynamiques comme les déplacements extérieurs.
      </p>
    </div>
    <div class="w-100 w-md-auto img-technologie">
      <img src="../img/ceinture.jpg" alt="Sons spatialisés" class="w-100 h-100 object-fit-cover">
    </div>
  </div>
</div>

<!-- Bloc 3 -->
<div class="col-md-12 mt-4">
  <div class="d-md-flex align-items-stretch bg-light rounded shadow-sm overflow-hidden" style="min-height: 200px;">
    <div class="flex-grow-1 p-4">
      <h4 class="fw-bold">Systèmes de capture et réalité augmentée</h4>
      <p class="text-justify">
        Pour concevoir et tester les technologies, le projet utilise des environnements numériques enrichis et ajustés en temps réel à l’aide de systèmes de capture de mouvement. Cela permet de simuler des espaces complexes dans lesquels les utilisateurs peuvent être guidés et orientés grâce à des signaux sensoriels. La réalité augmentée permet de modéliser précisément l’environnement, de détecter les interactions, et d’adapter les signaux aux mouvements et à l’attention de l’utilisateur, afin d’optimiser la fluidité d’usage et de personnalisation.
      </p>
    </div>
    <div class="w-100 w-md-auto img-technologie">
      <img src="../img/ceinture.jpg" alt="Réalité augmentée" class="w-100 h-100 object-fit-cover">
    </div>
  </div>
</div>

    
  </div>
</section>

<!-- Timeline -->
<section class="container my-5" style="max-width: 1500px; margin: 0 auto;">
  <h3 class="fw-bold mb-3 text-center">L’avancée du projet</h3>
  <div class="timeline-v2">
    
    <!-- 2021 -->
    <div class="timeline-row">
      <div class="timeline-year">2021</div>
      <div class="timeline-events">
        <div class="timeline-item">Lancement du projet SAM-Guide, financé par l’ANR, pour une durée de 48 mois.</div>
        <div class="timeline-item">Création du consortium pluridisciplinaire, réunissant chercheurs en neurosciences, ingénierie, informatique et ergonomie.</div>
        <div class="timeline-item">Définition des objectifs scientifiques, centrés sur le transcodage sensoriel et l’interaction spatiale sans vision.</div>
      </div>
    </div>

    <!-- 2022 -->
    <div class="timeline-row">
      <div class="timeline-year">2022</div>
      <div class="timeline-events">
        <div class="timeline-item">Premiers échanges en présentiel, avec le kick-off meeting à l’École Polytechnique.</div>
        <div class="timeline-item">Modélisation théorique du système de beacons 3D, base du langage spatial développé dans le projet.</div>
        <div class="timeline-item">Préparation des plateformes expérimentales en réalité augmentée et capture de mouvement.</div>
      </div>
    </div>

    <!-- 2023 -->
    <div class="timeline-row">
      <div class="timeline-year">2023</div>
      <div class="timeline-events">
        <div class="timeline-item">Développement des premiers prototypes de ceinture tactile et de sons spatialisés.</div>
        <div class="timeline-item">Premiers tests utilisateurs en environnement AR, pour évaluer la perception et la navigation.</div>
        <div class="timeline-item">Recrutements stratégiques (doctorants et ingénieurs) pour renforcer les équipes de Rouen, Caen et Grenoble.</div>
      </div>
    </div>

    <!-- 2024 -->
    <div class="timeline-row">
      <div class="timeline-year">2024</div>
      <div class="timeline-events">
        <div class="timeline-item">Validation des scénarios combinés : navigation, localisation d’objet, interaction dynamique.</div>
        <div class="timeline-item">Intégration de nouveaux algorithmes pour la détection de lignes, d’obstacles et la fusion de données.</div>
        <div class="timeline-item">Expérimentation sur des cas concrets, notamment via l’activité Laser-Run adaptée.</div>
      </div>
    </div>

    <!-- 2025 -->
    <div class="timeline-row">
      <div class="timeline-year">2025</div>
      <div class="timeline-events">
        <div class="timeline-item">Finalisation des dispositifs et protocoles pour un usage en conditions réelles.</div>
        <div class="timeline-item">Dissimulation et valorisation scientifique à travers publications et open source.</div>
        <div class="timeline-item">Exploration de nouvelles applications dans la mobilité, le sport et l’accessibilité urbaine.</div>
      </div>
    </div>

  </div>
</section>

<section class="container-fluid my-5 px-3 px-md-5">
  <h3 class="fw-bold mb-3 text-center">Applications Pratiques</h3>
  <div class="row g-4 justify-content-center">

    <!-- Bloc 1 -->
    <div class="col-lg-4">
      <div class="shadow rounded overflow-hidden h-100 d-flex flex-column">
        <img src="../img/schemaglobal.jpg" alt="Laser-Run" class="img-fluid w-100" style="object-fit: cover; height: 340px;">
        <div class="p-3 flex-grow-1 d-flex flex-column">
          <h5 class="fw-bold mb-2">Laser-Run</h5>
          <p class="fs-6 text-justify">
            Le Laser-Run adapté est une application concrète du projet SAM-Guide, pensée comme un terrain d’expérimentation ludique et sensorielle pour les personnes aveugles ou malvoyantes.
          </p>
        </div>
      </div>
    </div>

    <!-- Bloc 2 -->
    <div class="col-lg-4">
      <div class="shadow rounded overflow-hidden h-100 d-flex flex-column">
        <img src="../img/illustrationmobilite.png" alt="Entraînement mobilité" class="img-fluid w-100" style="object-fit: cover; height: 340px;">
        <div class="p-3 flex-grow-1 d-flex flex-column">
          <h5 class="fw-bold mb-2">Entraînement à la mobilité</h5>
          <p class="fs-6 text-justify">
            Les dispositifs SAM-Guide peuvent être utilisés dans des parcours de formation ou de rééducation pour aider à l'apprentissage de la navigation autonome en intérieur comme en extérieur.
          </p>
        </div>
      </div>
    </div>

    <!-- Bloc 3 -->
    <div class="col-lg-4">
      <div class="shadow rounded overflow-hidden h-100 d-flex flex-column">
        <img src="../img/illustrationenville.png" alt="Navigation urbaine" class="img-fluid w-100" style="object-fit: cover; height: 340px;">
        <div class="p-3 flex-grow-1 d-flex flex-column">
          <h5 class="fw-bold mb-2">Navigation urbaine assistée</h5>
          <p class="fs-6 text-justify">
            Ces technologies pourront être adaptées à des systèmes de guidage en ville ou dans des lieux complexes, pour renforcer l'autonomie au quotidien.
          </p>
        </div>
      </div>
    </div>

  </div>
</section>


<section class="container my-5">
  <h3 class="fw-bold mb-4 text-center">Publications scientifiques</h3>
  
  <ul class="ps-3 publication-list">
    <li>
      Faugloire, E., Lejeune, L., Rivière, M.-A., & Mantel, B. (2022). <br>
      Spatiotemporal Influences on the Recognition of Two-dimensional Vibrotactile Patterns on the Abdomen. <br>
      <em>Journal of Experimental Psychology: Applied, 28</em>(3), 606–628. <br>
      <a href="https://doi.org/10.1037/xap0000404" target="_blank">https://doi.org/10.1037/xap0000404</a>
    </li>

    <li class="mt-3">
      Morice, A., Mantel, B. & Faugloire, E. (2022). <br>
      Assistance vibrotactile à l’interception locomotrice de cibles mobiles : étude de faisabilité. <br>
      56e congrès de la Société d’Ergonomie de Langue Française. : 
      <a href="https://hal.science/hal-03759604/" target="_blank">https://hal.science/hal-03759604/</a>
    </li>

    <li class="mt-3">
      Mantel, B. & Faugloire, E. (2022). <br>
      Conditions de l’incorporation d’un objet. Point de vue d’une approche incarnée de la perception <br>
      20e congrès de l’Association des Chercheurs en Activités Physiques et Sportives. : 
      <a href="https://normandie-univ.hal.science/hal-04622055v1" target="_blank">https://normandie-univ.hal.science/hal-04622055v1</a>
    </li>

    <li class="mt-3">
      Mantel, B. & Faugloire, E. (2023). <br>
      Perspective écologique sur la cognition incarnée. <br>
      20e congrès de l’Association des Chercheurs en Activités Physiques et Sportives. : 
      <a href="https://hal.science/hal-04626303v1" target="_blank">https://hal.science/hal-04626303v1</a>
    </li>

    <li class="mt-3">
      Fons, Huet, Pellerin, Gerber, Graff (2023) <br>
      Moving Towards and Reaching a 3-d Target by Embodied Guidance: Parsimonious vs Explicit Sound Metaphors : 
      <a href="https://hal.univ-grenoble-alpes.fr/hal-04192144" target="_blank">https://hal.univ-grenoble-alpes.fr/hal-04192144</a>
    </li>

    <li class="mt-3">
      Fons, Huet, Pellerin, Graff (2024) <br>
      Using Fitts Law to Compare Sonification Guidance Methods for Target Reaching Without Vision : 
      <a href="https://hal.univ-grenoble-alpes.fr/hal-04492351" target="_blank">https://hal.univ-grenoble-alpes.fr/hal-04492351</a>
    </li>

    <li class="mt-3">
      Fons, Huet, Pellerin, Graff (2025) <br>
      Dissociate Dimensions to Improve Sound Metaphors Guiding the Hand Towards 3D Non-visible Targets : 
      <a href="https://hal.science/hal-05034749v1" target="_blank">https://hal.science/hal-05034749v1</a>
    </li>
  </ul>

  <p class="mt-4 fw-bold align">
    Voir la liste : 
    <a href="https://anr.hal.science/search/index/?q=*&anrProjectReference_s=ANR-21-CE33-0011" target="_blank">
      https://ans.hal.science/search/index/?q=%anrProjectReference_s:ANR-21-CE33-0011
    </a>
  </p>
</section>

</main>
      
      <footer class="custom-site-footer text-center text-lg-start mt-auto border-top pt-4">
        <div class="container">

          <!-- Liens -->
          <div class="d-flex justify-content-center gap-5 mt-2 mb-3 flex-wrap flex-column flex-md-row">
            <a href="../index.html" class="text-decoration-none text-dark">Accueil</a>
            <a href="#" class="text-decoration-none text-dark">Projet</a>
            <a href="../html/consortium.html" class="text-decoration-none text-dark">Consortium</a>
            <a href="../html/actualites.html" class="text-decoration-none text-dark">Actualités</a>
            <a href="../html/annonces.html" class="text-decoration-none text-dark">Annonces</a>
            <a href="../html/faq.html" class="text-decoration-none text-dark">FAQ</a>
            <a href="../html/contact.html" class="text-decoration-none text-dark">Contact</a>
            <a href="../html/jeu.html" class="text-decoration-none text-dark">Jeu Interactif</a>
          </div>
      
          <!-- Mentions légales -->
          <p class="custom-mention text-muted small mb-0">&copy; Tous droits réservés – SAM-Guide</p>
        </div>
      
        <!-- Logo en bas à droite -->
        <div class="position-relative">
          <a href="https://anr.fr/" target="_blank"><img src="../img/logo_anr.png" alt="Logo ANR" class="img-anr position-absolute bottom-0" style="width: 150px; height: auto;"></a>
        </div>
      </footer>
      
    <script src="../js/menu_burger.js"></script> 
</body>
</html>